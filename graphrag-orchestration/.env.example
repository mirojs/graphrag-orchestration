# GraphRAG Orchestration Service Configuration

# Azure OpenAI (Required for LLM-based extraction)
AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key-here
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o  # Primary model for synthesis and general queries
# Optional: use a faster model just for DRIFT (e.g., gpt-4o-mini)
# If set, DRIFT will use this instead of AZURE_OPENAI_DEPLOYMENT_NAME
# AZURE_OPENAI_DRIFT_DEPLOYMENT_NAME=gpt-4o-mini

# Specialized deployments for optimized operations (Optional - uses primary if not set)
# AZURE_OPENAI_INDEXING_DEPLOYMENT=gpt-4-turbo-2024-04-09  # Use when GPT-4.1 available: 1M context window for indexing
# AZURE_OPENAI_ROUTING_DEPLOYMENT=gpt-4o  # Use when GPT-5.2 available: System 2 reasoning for query routing

AZURE_OPENAI_MODEL_VERSION=2024-11-20
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-large  # Migrate to text-embedding-3-small for cost optimization
AZURE_OPENAI_EMBEDDING_DIMENSIONS=1536  # Change to 1536 when using text-embedding-3-small
AZURE_OPENAI_API_VERSION=2024-10-21

# OR use Managed Identity (deployed environment)
# AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com/
# Leave AZURE_OPENAI_API_KEY empty to use DefaultAzureCredential

# Neo4j Graph Database (Required)
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password-here

# Vector Store (choose one)
VECTOR_STORE_TYPE=lancedb
LANCEDB_PATH=./data/lancedb

# Azure AI Search (alternative to LanceDB)
# VECTOR_STORE_TYPE=azure_search
# AZURE_SEARCH_ENDPOINT=https://your-search.search.windows.net
# AZURE_SEARCH_API_KEY=your-api-key-here
# AZURE_SEARCH_INDEX_NAME=graphrag-index

# Cosmos DB for Schema Vault (Optional - for schema reuse)
COSMOS_ENDPOINT=https://your-cosmos.documents.azure.com:443/
COSMOS_KEY=your-cosmos-key-here
COSMOS_DATABASE_NAME=content-processor

# ============================================================================
# DOCUMENT INGESTION SERVICES (Choose based on your needs)
# ============================================================================

# Option 1: Azure Document Intelligence (RECOMMENDED - Production-ready)
# Most stable, mature service for document layout extraction
# Native Python SDK, managed identity support, enterprise SLA
# Preferred (Managed Identity / Entra ID): requires the resource's custom subdomain endpoint
AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://<your-di-resource-name>.cognitiveservices.azure.com/
# Leave KEY empty in deployed environments to use managed identity
AZURE_DOCUMENT_INTELLIGENCE_KEY=
# Alternative (API key auth): regional endpoint works, but requires a key
# AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://<your-region>.api.cognitive.microsoft.com/
# AZURE_DOCUMENT_INTELLIGENCE_KEY=your-api-key-here
AZURE_DOC_INTELLIGENCE_API_VERSION=2024-11-30
# For deployed environments, prefer managed identity with the custom subdomain endpoint

# Option 2: LlamaParse (Alternative - Great for non-Azure environments)
# Get your free API key from https://cloud.llamaindex.ai/
LLAMA_CLOUD_API_KEY=llx-your-api-key-here

# Option 3: Azure Content Understanding (DEPRECATED - Legacy support only)
# Less stable than Document Intelligence, not recommended for new projects
AZURE_CONTENT_UNDERSTANDING_ENDPOINT=https://your-cu.api.cognitive.microsoft.com/
AZURE_CONTENT_UNDERSTANDING_API_KEY=your-api-key-here
AZURE_CU_API_VERSION=2025-11-01

# Data Directories (local development)
GRAPHRAG_DATA_DIR=./data/graphrag
GRAPHRAG_CACHE_DIR=./data/cache

# Multi-tenancy
ENABLE_GROUP_ISOLATION=true

# ============================================================================
# PERFORMANCE & RATE LIMITING
# ============================================================================

# Number of parallel workers for entity extraction
# Set to 1 for serial processing (works with 10K TPM - current limit)
# Set to 4 for parallel processing (requires 50K+ TPM)
# Default: 1 (safe for low rate limits)
GRAPHRAG_NUM_WORKERS=1
