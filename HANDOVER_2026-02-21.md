# Handover — 2026-02-21

## Current State

Route 5 Unified Search benchmark: **54/57 (94.7%)** on the 19-question R4 question bank.
Up from **51/57 (89.5%)** at the start of today's session.

All changes are committed and deployed. Branch: `main`. No staged changes.

---

## What Was Done Today

### Bugs Fixed

1. **Missing `source` field in sentence evidence** (commit `fa2e478`)
   - File: `src/worker/hybrid_v2/routes/route_5_unified.py` ~line 735
   - Bug: `_retrieve_sentence_evidence()` Cypher returns `sent.source` but the evidence dict never included it. So `ev.get("source")` in `_denoise_sentences()` always returned `None`, and the `_STRUCTURED_SOURCES` bypass for `source="signature_party"` sentences never fired. Signature block sentences were always hard-removed by the denoiser.
   - Fix: Added `"source": r.get("source", "")` to the evidence dict (1-line fix).

2. **Signature block content not reaching LLM context** (commits `920ae4a`, `c6b576d`, `fca2606`, `fd8cbc3`)
   - File: `src/worker/hybrid_v2/routes/route_5_unified.py` ~lines 886-962, 418-426, 459-467
   - Problem: Purchase contract Exhibit A (signature block with "Contoso Ltd.", "Fabrikam Inc.", date "04/30/2025") was never retrieved for entity-counting queries (Q-D8) because vector search ranks signature text poorly for those query types, and PPR chunk allocation deprioritizes them.
   - Fix: Added `_retrieve_signature_chunks()` method that queries Neo4j directly for TextChunks containing "Authorized Representative" or "Signed this" text. These chunks are merged into `coverage_chunks` alongside sentence evidence before synthesis.
   - Sub-bug found during implementation: The Cypher used `PART_OF` edge but hybrid_v2 schema uses `IN_DOCUMENT` for TextChunk→Document relationships. Fixed in `fd8cbc3`.

3. **Reverted counterproductive entity-tracking prompt** (commit `fa2e478`)
   - File: `src/worker/hybrid_v2/pipeline/synthesis.py`
   - The `_entity_tracking_patterns` regex list, `is_entity_tracking_query` detection, and "IMPORTANT for Entity-Document Tracking" guidance block were causing Q-D8 regressions (hardcoded entity names in the prompt biased the LLM). Removed entirely.

### Commits (chronological)

```
fa2e478  fix(retrieval): pass sentence source field to denoiser
920ae4a  feat(retrieval): add guaranteed signature block retrieval for Route 5
c6b576d  fix(retrieval): fetch parent TextChunks for signature block coverage
fca2606  fix(retrieval): use content-based matching for signature block chunks
fd8cbc3  fix(retrieval): use IN_DOCUMENT edge (not PART_OF) for chunk→document
```

---

## Score Trajectory

| State | Q-D3 | Q-D7 | Q-D8 | Total | Notes |
|-------|------|------|------|-------|-------|
| Start of day (entity prompt active) | 2/3 | 1/3 | 0/3 | 51/57 | Entity prompt hurt Q-D8 |
| + Source fix + prompt revert (`fa2e478`) | — | 3/3 | — | — | Q-D7 fixed |
| + Sentence retrieval (`920ae4a`) | — | — | — | — | Wrong granularity (sentences too short) |
| + TextChunk via PART_OF (`c6b576d`) | — | — | — | — | Wrong edge type |
| + Content-based (`fca2606`) | — | — | — | — | Still had PART_OF bug |
| **Final: + IN_DOCUMENT fix (`fd8cbc3`)** | **2/3** | **3/3** | **1/3** | **54/57** | Exhibit A in 3/3 Q-D8 runs |

---

## LLM Judge Results — Final Benchmark

Source: `benchmarks/route5_unified_r4questions_20260221T110522Z.json`
Eval:   `benchmarks/route5_unified_r4questions_20260221T110522Z.eval.md`

| QID | Score | Notes |
|-----|-------|-------|
| Q-D1 | 3/3 | Emergency defect notification |
| Q-D2 | 3/3 | Confirmed reservations on termination |
| Q-D3 | 2/3 | Time windows — misses 60-day repair window |
| Q-D4 | 3/3 | Insurance limits |
| Q-D5 | 3/3 | Coverage start/end |
| Q-D6 | 3/3 | Price matching |
| Q-D7 | 3/3 | Latest date (was 1/3) |
| Q-D8 | 1/3 | Entity document count (was 0/3) |
| Q-D9 | 3/3 | Fee structures |
| Q-D10 | 3/3 | Risk allocation |
| Q-N1–N10 | 27/27 | All negative tests pass |
| **Total** | **54/57** | **94.7%** |

---

## Remaining Issues — TODO

### 1. Q-D8 still scores 1/3 — LLM miscounts entity appearances

- **Status:** Retrieval solved, synthesis problem remains.
- **Detail:** The Exhibit A signature block (with "Contoso Ltd." and "Fabrikam Inc.") is now in the LLM context for ALL 3 runs. Run 1 correctly answers "tied at 4 each". Runs 2-3 give contradictory reasoning — the LLM says "Contoso Ltd. appears in more" but then counts Fabrikam at 5 and concludes Fabrikam wins.
- **Root cause:** This is a synthesis/reasoning limitation. The LLM has the right data but miscounts across 5 document sections. Possible approaches:
  - Add a structured entity-document matrix to the prompt context
  - Pre-compute entity-to-document mappings in the retrieval layer and inject a summary table
  - Prompt engineering to instruct explicit enumeration before comparison
- **Risk:** Any prompt changes here could affect other questions. Entity-tracking prompt was already tried and reverted because it caused regressions.

### 2. Q-D3 still scores 2/3 — missing 60-day repair window

- **Status:** Stable at 2/3 across sessions. Not a regression.
- **Detail:** The "60-day repair window after defect report" timeframe from the warranty document is consistently missed. The LLM gets most other timeframes correct.
- **Possible approach:** This likely requires either better chunk selection for the warranty document or additional retrieval that specifically targets "repair window" / "defect report" text.

### 3. Unstaged script changes (not blocking)

Two script files have uncommitted modifications:
- `scripts/benchmark_route3_global_search.py` — Adds Route 7 (HippoRAG 2) as a `--force-route` option
- `scripts/evaluate_route4_reasoning.py` — Fixes multi-line ground truth parsing (was only capturing first line of multi-line expected answers)

These are utility improvements; commit when convenient.

### 4. Route 7 (HippoRAG 2) type annotation (not blocking)

- `src/worker/hybrid_v2/routes/route_7_hipporag2.py` has a return type annotation change (`Dict[str, List[Dict]]` -> `List[Dict]`) that was deliberately not staged. Minor cleanup.

---

## Key Files Reference

| File | Purpose |
|------|---------|
| `src/worker/hybrid_v2/routes/route_5_unified.py` | Route 5 main pipeline — PPR + sentence vector search + signature block retrieval |
| `src/worker/hybrid_v2/pipeline/synthesis.py` | LLM synthesis prompt construction |
| `src/worker/hybrid_v2/pipeline/chunk_filters.py` | Noise filters, min-content penalty, filled-label exemption |
| `src/worker/hybrid_v2/indexing/dual_index.py` | Defines graph schema including `(:TextChunk)-[:IN_DOCUMENT]->(:Document)` |
| `src/worker/hybrid_v2/indexing/text_store.py` | TextChunk storage and `IN_DOCUMENT` relationship creation |
| `scripts/benchmark_route5_unified_r4_questions.py` | 19-question benchmark runner |
| `scripts/evaluate_route4_reasoning.py` | LLM judge evaluation (gpt-5.1) |
| `benchmarks/route5_unified_r4questions_*.json` | Benchmark result files |

## Key Architecture Notes

- **Sentence denoising** (`_denoise_sentences()` in route_5_unified.py) hard-removes sentences matching patterns like "signature", "signed this", "authorized representative". The bypass is via `_STRUCTURED_SOURCES` set containing `"signature_party"`. For the bypass to work, the `source` field must be present in the evidence dict (this was the bug fixed in `fa2e478`).
- **Signature block chunk retrieval** (`_retrieve_signature_chunks()`) runs a content-based Cypher query rather than relying on `source="signature_party"` tagging, because the purchase contract's Exhibit A page was not tagged with that source during indexing. The method uses `chunk.text CONTAINS 'Authorized Representative' OR chunk.text CONTAINS 'Signed this'`.
- **Coverage chunks** are merged with sentence evidence and passed to the synthesizer alongside PPR-retrieved entity chunks. They go through MD5 + Jaccard deduplication (threshold 0.92) against entity-retrieved chunks.
- **hybrid_v2 graph schema**: `(:TextChunk)-[:IN_DOCUMENT]->(:Document)`, NOT `PART_OF`. The `PART_OF` edge is used for `(:Sentence)-[:PART_OF]->(:TextChunk)`.

---

## How to Run Benchmarks

```bash
# Full 19-question benchmark with 3 repeats (includes LLM context for debugging)
python3 scripts/benchmark_route5_unified_r4_questions.py --repeats 3 --include-context

# Targeted single-question benchmark
python3 scripts/benchmark_route5_unified_r4_questions.py --repeats 3 --include-context --filter-qid Q-D8

# LLM judge evaluation
python3 scripts/evaluate_route4_reasoning.py benchmarks/route5_unified_r4questions_<timestamp>.json

# Deploy to Azure Container Apps
az containerapp update -n graphrag-api -g graphrag-rg --image <acr>.azurecr.io/graphrag-api:latest
```
