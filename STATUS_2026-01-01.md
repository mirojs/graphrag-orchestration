# Status Report - January 1, 2026

## Current Context

### What We're Working On
Testing and evaluating **LazyGraphRAG Route 3 (Global Search)** within the hybrid system, specifically:
- NLP mode vs NLP + sentence connection mode
- Determinism and readability of outputs
- Ensuring tests are running against **hybrid endpoints** (`/hybrid/query`), not V3 GraphRAG endpoints

### Key Realization from Today
- Earlier benchmark runs were mistakenly executed against **V3 GraphRAG endpoints** (`/graphrag/v3/query/global/*`)
- V3 endpoints use "community summaries" which are NOT part of LazyGraphRAG
- User clarified: **"all v3 apis are not related"** to LazyGraphRAG testing
- The correct system to test is under `/hybrid/` (the LazyGraphRAG/hybrid orchestrator)

### Test Suite Locations

#### Hybrid (LazyGraphRAG) Tests
1. **`graphrag-orchestration/tests/e2e_test_hybrid_qa.py`**
   - E2E tests for hybrid endpoints (`/hybrid/query`, `/hybrid/query/drift`)
   - Currently has:
     - Route 2 (local_search) forced-route test
     - Route 4 (drift) test via `/hybrid/query/drift`
   - **Missing**: Route 3 (global_search) explicit forced-route test
   - Requires: Neo4j + Azure OpenAI + HippoRAG index configured

2. **`graphrag-orchestration/tests/test_hybrid_router_question_bank.py`**
   - Routing-only tests (no actual `/hybrid/query` execution)
   - Tests router decision logic for different profiles
   - Mentions `GLOBAL_SEARCH` only in comments

3. **Cloud test suite**: `tests/cloud/test_cloud_question_bank.py`
   - Not yet examined in detail
   - May contain actual hybrid Route 3 execution tests

#### Non-Hybrid Tests (Older GraphRAG-style)
- `tests/integration/test_route_3_global.py` - Mock-based tests for Route 3 structure (community summaries, RAPTOR, map-reduce)
- `tests/unit/test_router.py` - Router unit tests
- All tests pass but are mock-based, not actual endpoint integration

### Benchmark Scripts Used Previously
Located in `scripts/`:
- `benchmark_route3_graph_vs_route4_drift.py` - **Tests V3 endpoints** (not hybrid)
- `benchmark_all4_routes_posneg_qbank.py` - **Tests V3 endpoints** (not hybrid)

Generated outputs in `benchmarks/`:
- `route3_global_nlp_vs_llm_qg10_20260101T*.{json,md}` - V3 endpoint results
- `route3_global_audit_vs_client_repeat_qg10_20260101T*.{json,md}` - V3 endpoint results
- `route3_global_audit_vs_client_connected_qg10_20260101T*.{json,md}` - V3 endpoint results

**Problem**: All these benchmarks were run against V3, which is not LazyGraphRAG.

## Hybrid Route 3 Implementation

### Code Locations
- **Orchestrator**: `graphrag-orchestration/app/hybrid/orchestrator.py`
  - Method: `_execute_route_3_global_search(query, response_type)`
  - Logs: `route_3_global_search_start`
  - Returns: `route_used: "route_3_global_search"`

- **Router**: `graphrag-orchestration/app/routers/hybrid.py`
  - Endpoints: `/hybrid/query`, `/hybrid/query/drift`
  - Route enum: `QueryRoute.GLOBAL_SEARCH = "global_search"`

### Route 3 Modes (Based on Earlier Discussion)
User mentioned testing:
1. **LLM mode** first
2. **NLP mode**
3. **NLP + sentence connection mode**

The "new test" outputs scores like `1 / 0.5 / 0.3` (determinism metrics).

## What We Were Looking For

### Immediate Question
**"list all the route 3 tests under hybrid"**

### Finding
- Only **one file** posts to `/hybrid/query`: `graphrag-orchestration/tests/e2e_test_hybrid_qa.py`
- That file has NO explicit Route 3 forced-route test (only Route 2 and Route 4)
- The cloud test suite (`tests/cloud/`) was not yet examined

### User's Frustration
"all tests are there and you've been using them for a few hours and now you coun't find them. it's stupid"

**Implication**: The actual hybrid Route 3 tests that have been used are likely in:
1. `tests/cloud/test_cloud_question_bank.py` (not yet examined)
2. Or standalone benchmark scripts that call hybrid endpoints (not found yet)

## To-Do List for Tomorrow

### Priority 1: Find the Actual Hybrid Route 3 Tests
- [ ] **Examine `tests/cloud/test_cloud_question_bank.py`** in detail
  - Check if it calls `/hybrid/query` with `force_route: "global_search"`
  - Check if it tests NLP modes and sentence connection
- [ ] **Search for any standalone scripts** that call hybrid endpoints (not V3)
  - Look for scripts that post to `/hybrid/query`
  - Look for scripts that test "NLP" vs "sentence connection"
- [ ] **Review conversation history** to find exact script/test names that were run

### Priority 2: Understand Route 3 NLP Modes
- [ ] **Read `_execute_route_3_global_search` implementation** in `graphrag-orchestration/app/hybrid/orchestrator.py`
  - Identify what "NLP mode" means in the code
  - Identify what "sentence connection" parameter/flag controls
  - Look for `synthesize=true` or similar flags
- [ ] **Check if there are parameters** like:
  - `use_nlp_only=true/false`
  - `enable_sentence_connection=true/false`
  - `synthesis_mode="nlp"|"llm"`

### Priority 3: Create/Run Hybrid Route 3 Tests
- [ ] **If no hybrid Route 3 test exists**: Create one in `e2e_test_hybrid_qa.py`
  - Pattern: `force_route: "global_search"`, assert `route_used == "route_3_global_search"`
- [ ] **If test exists but wasn't found**: Run it with proper environment setup
- [ ] **Run benchmark** comparing NLP vs NLP+sentence-connection on hybrid endpoints

### Priority 4: Document the Confusion
- [ ] **Create a clear mapping**:
  - V3 GraphRAG endpoints → community summaries, NOT LazyGraphRAG
  - Hybrid endpoints → LazyGraphRAG, the system we're testing
  - Route 3 in hybrid → global search without community summaries
- [ ] **Update any README/documentation** to clarify this distinction

## Environment Setup Needed for E2E Tests

From `e2e_test_hybrid_qa.py` requirements:
1. **Neo4j**: Must be configured with indexed data
   - Set `E2E_GROUP_ID` to a tenant with data
2. **Azure OpenAI**: LLM client for synthesis
   - Disambiguator and synthesizer must be "ok"
3. **HippoRAG index**: Must be synced
   - `entity_texts.json` must exist and be non-empty
4. **Environment variable**: `RUN_E2E_TESTS=1` to enable tests

## Recent Commands (Last Hour)
```bash
# Searched for hybrid tests
file_search: **/*hybrid*test*.py → no results
grep_search: route_3_global_search → found orchestrator.py, e2e_test_hybrid_qa.py

# Listed test directories
list_dir: tests/ → found cloud/, integration/, unit/
list_dir: graphrag-orchestration/tests/ → found 8 test files

# Ran integration tests
pytest tests/integration/test_route_3_global.py -v → 25 passed (mock-based)

# Tried E2E tests (failed - no Neo4j)
RUN_E2E_TESTS=1 pytest graphrag-orchestration/tests/e2e_test_hybrid_qa.py -v -s
```

## Key Files to Review Tomorrow
1. `tests/cloud/test_cloud_question_bank.py` ← **START HERE**
2. `graphrag-orchestration/app/hybrid/orchestrator.py` (lines 311-370: `_execute_route_3_global_search`)
3. Any benchmark scripts that actually call `/hybrid/query` (not `/graphrag/v3/`)

## Questions to Answer
1. Where are the hybrid Route 3 tests that have been "used for hours"?
2. What parameter controls NLP vs NLP+sentence-connection in hybrid Route 3?
3. Should we create new benchmark scripts for hybrid endpoints, or do they exist already?
