# Session Handover — 2026-02-19 v2

**Focus:** Flat-pool seed architecture implementation, deployment, and benchmark validation for Route 5

---

## 1. Strategic Context

Route 4 currently achieves **100% theme coverage** but relies on fragile mechanisms:
- **LLM query decomposition** — breaks query into sub-questions, fragile to prompt sensitivity
- **Coverage gap fill** — 200-line band-aid ensuring every document gets at least one chunk

The goal is to make Route 4 **future-proof** by replacing these with 3 robust addon seeds covering complementary scales. Route 5 serves as the **test bed** for this architecture before porting to Route 4.

### Three Addon Seeds (Gap Fills at Seed Level)

| Addon | Scale | Source | Purpose |
|-------|-------|--------|---------|
| **Community** | Macro | Embedding-match communities → extract member entities | Recovers cross-doc entity references that NER's LLM bottleneck drops |
| **Structural** | Meso | Embedding-match section headers → extract section entities | Genuinely new signal — NER has no section awareness |
| **Semantic** | Micro | Top reranked sentences → traverse `(Sentence)-[:MENTIONS]->(Entity)` | Recovers entity-sentence associations dropped by NER |

### Key Architectural Decisions

- NER is the **primary** seed source; addons are **gap fills** at the seed level (top of pipeline)
- All seeds get **equal weight** — no weighted tiers, no probability distribution
- Seeds are **deduped via set union** by entity ID
- Community and semantic signals already exist inside NER (community summaries as LLM context, Strategy 6 vector fallback) — the addons recover what NER's LLM bottleneck drops
- `ROUTE5_SEED_MODE=flat` env var toggles between old weighted (v5.0) and new flat mode (v5.1-flat)

---

## 2. Implementation (Completed)

### Commit: `83ee2de` — `feat: add flat-pool seed mode for Route 5 PPR (ROUTE5_SEED_MODE=flat)`

**File 1: `src/worker/services/async_neo4j_service.py`**
- Added `get_entities_by_sentence_ids()` method (~line 1373)
- Cypher: `UNWIND sentence_ids → MATCH (Sentence)-[:MENTIONS]->(Entity) → ORDER BY degree DESC → cap per sentence`
- Returns `DISTINCT` entity records (id, name, sentence_id)

**File 2: `src/worker/hybrid_v2/pipeline/seed_resolver.py`**
- Added `resolve_flat_seed_pool()` function (~line 844)
- Four inner async functions: `_resolve_ner()`, `_resolve_community_addon()`, `_resolve_structural_addon()`, `_resolve_semantic_addon()`
- All 4 run via `asyncio.gather()`, results merged via set union (dedup by entity ID)
- Returns diagnostics: per-source counts, exclusive counts, overlaps

**File 3: `src/worker/hybrid_v2/routes/route_5_unified.py`**
- `ROUTE5_SEED_MODE` env var check at Step 0 (default `"weighted"`)
- Flat mode: calls `resolve_flat_seed_pool()` → `personalized_pagerank_native()` with damping=0.85
- Weighted mode: calls `resolve_all_tiers()` → `personalized_pagerank_weighted()` with dynamic damping
- Flat mode has seed cap (`ROUTE5_MAX_FLAT_SEEDS`, default 30) with priority: NER > semantic > structural > community
- Metadata: `seed_mode: "flat"`, `version: "v5.1-flat"`, `pool_metadata` with per-source breakdown

**File 4: `deploy-graphrag.sh`** (modified)
- Added `ROUTE5_SEED_MODE` to the ENV_VARS array for deployment

---

## 3. Deployment (Completed)

- Image tag: `d9b9f92-05`
- Both `graphrag-api` and `graphrag-worker` updated
- `ROUTE5_SEED_MODE=flat` set on both container apps
- Server healthy, revision `graphrag-api--0000076` running with 100% traffic
- API URL: `https://graphrag-api.salmonhill-df6033f3.swedencentral.azurecontainerapps.io`

---

## 4. Benchmark Results (v5.1-flat)

**Full 19-question benchmark:** `benchmarks/route5_unified_r4questions_20260219T181059Z.json`
**LLM Judge evaluation:** `benchmarks/route5_unified_r4questions_20260219T181059Z.eval.md`

### LLM Judge Summary: 52/57 (91.2%) — Pass Rate: 94.7% (18/19)

| QID | Score | Containment | Notes |
|-----|-------|-------------|-------|
| Q-D1 | 3/3 | 0.94 | Pass |
| Q-D2 | 3/3 | 1.00 | Pass |
| Q-D3 | 2/3 | 0.74 | Pass (improved from 0.60 weighted). Finds 180-day thresholds now. Still misses PC 5-biz-day and 3-biz-day cancel. |
| Q-D4 | 3/3 | 0.95 | Pass |
| Q-D5 | 3/3 | 0.93 | Pass |
| Q-D6 | 3/3 | 0.70 | Pass |
| Q-D7 | 0/3 | 0.83 | **FAIL** — identifies Holding Tank (2024-06-15) instead of Purchase Contract (2025-04-30) |
| Q-D8 | 2/3 | 0.64 | Pass. Says 3 docs instead of 4 (misses Purchase Contract) |
| Q-D9 | 3/3 | 0.96 | Pass |
| Q-D10 | 3/3 | 0.97 | Pass |
| Q-N1–N10 | 3/3 each | — | All 9 negative tests pass |

### Comparison: Flat vs Weighted

Same total score (52/57, 94.7% pass rate). No regressions. Q-D3 containment improved (0.60→0.74). Q-D7 still fails in both modes.

---

## 5. Semantic Addon Returns 0 Seeds (Known Issue)

**Root cause confirmed via Neo4j query:**

```
Sentence -[:MENTIONS]-> Entity count: 0
TextChunk -[:MENTIONS]-> Entity count: 286
```

The test dataset (`test-5pdfs-v2-fix2`) was indexed with the **chunk-based pipeline**. All 286 MENTIONS edges go from `TextChunk` to `Entity`. Zero `(Sentence)-[:MENTIONS]->(Entity)` edges exist.

The semantic addon's Cypher traverses `(Sentence)-[:MENTIONS]->(Entity)`, so it returns nothing.

**Resolution:** The semantic addon will automatically activate when data is re-indexed with the **sentence-based pipeline** (which writes Sentence IDs to `text_unit_ids` instead of TextChunk IDs). No code change needed.

---

## 6. NER Pipeline Analysis

- **NER is LLM-based (gpt-4o)**, receives top-10 community summaries (200 chars each) as context
- **Proper noun filter** (`has_upper or has_digit`) is the final gate — kills concept extraction
- **Strategy 6 vector fallback** has no minimum similarity threshold
- For failing queries:
  - Q-D3: NER returns `[]` (empty) — 0 T1 seeds
  - Q-D7: NER returns `["Latest Explicit Date Document"]` (hallucinated) — garbage seeds from vector fallback
  - Q-D8: NER returns `["Fabrikam Inc.", "Contoso Ltd."]` — works correctly
- Community and semantic signals already feed INTO NER, but the LLM bottleneck drops them. The addons recover this dropped signal.

---

## 7. Route 4 Architecture Notes (Reference)

- **Community peer augmentation:** Dead code in the active path. Lives in `_trace_with_async_neo4j()` but Route 4 uses `trace_semantic_beam()` which bypasses it. Only fires with `ROUTE4_USE_PPR=True`.
- **Coverage gap fill:** 200-line band-aid ensuring every document gets at least one chunk. Architecture doc calls it compensation for "weak entity extraction."
- **Query decomposition:** Breaks query into 2-5 sub-questions via LLM. Route 5 dropped this.
- **Route 4 seed flow:** Query decomposition → NER each sub-question → flat list + community peer augmentation → coverage gap fill → PPR with equal weight, fixed damping 0.85

---

## 8. Files Modified This Session

| File | Change |
|------|--------|
| `src/worker/services/async_neo4j_service.py` | Added `get_entities_by_sentence_ids()` |
| `src/worker/hybrid_v2/pipeline/seed_resolver.py` | Added `resolve_flat_seed_pool()` |
| `src/worker/hybrid_v2/routes/route_5_unified.py` | Added `ROUTE5_SEED_MODE` toggle (flat vs weighted) |
| `deploy-graphrag.sh` | Added `ROUTE5_SEED_MODE` to ENV_VARS array |

---

## 9. Benchmark Files Produced Today

| File | Description |
|------|-------------|
| `benchmarks/route5_unified_r4questions_20260219T124958Z.*` | Pre-flat baseline (weighted mode, sub-section fix) |
| `benchmarks/route5_unified_r4questions_20260219T151040Z.*` | Full 19Q weighted mode + LLM judge (94.7% pass) |
| `benchmarks/route5_unified_r4questions_20260219T180758Z.json` | Q-D7 single test (flat mode, post-deploy) |
| `benchmarks/route5_unified_r4questions_20260219T181059Z.*` | **Full 19Q flat mode + LLM judge (94.7% pass)** |

---

## 10. TODO List

### Completed
- [x] Implement `get_entities_by_sentence_ids()` in async_neo4j_service.py
- [x] Implement `resolve_flat_seed_pool()` in seed_resolver.py
- [x] Wire `ROUTE5_SEED_MODE` toggle in route_5_unified.py
- [x] Add `ROUTE5_SEED_MODE` to deploy-graphrag.sh
- [x] Commit and push (`83ee2de`)
- [x] Deploy to remote server (image `d9b9f92-05`)
- [x] Run full 19Q benchmark with flat mode
- [x] Run LLM judge evaluation
- [x] Investigate semantic addon returning 0 (confirmed: no Sentence MENTIONS edges in graph)

### Remaining / Next Steps
- [ ] **Re-index test data with sentence-based pipeline** to create `(Sentence)-[:MENTIONS]->(Entity)` edges, enabling the semantic addon
- [ ] **Re-run benchmark after re-indexing** to measure semantic addon impact
- [ ] **Fix Q-D7 (Purchase Contract blind spot):** The PC date (2025-04-30) is not reached by any addon. Options:
  - Re-index with sentence pipeline (semantic addon may find PC sentences)
  - Relax NER proper-noun filter to allow concept extraction
  - Ensure structural sections match PC-specific headers
- [ ] **Port flat-pool architecture to Route 4** once validated on Route 5 — replace decomposition + coverage gap fill with the 3 addon seeds
- [ ] **Evaluate NER improvements independently** — relaxing proper-noun filter, improving community summary context
- [ ] **Consider creating `(Sentence)-[:MENTIONS]->(Entity)` edges retroactively** via a migration script (traverse from `TextChunk→MENTIONS→Entity` and map chunk sentences) instead of full re-indexing
