# Session Handover — 2026-02-10

**Last commit:** `d2cc988e` on `main` (pushed to remote)  
**Session focus:** Citation explosion fix, doc-scope retrieval, chunking strategy analysis  

---

## What Was Completed Today

### 1. Citation Explosion Structural Fix ✅

**Problem:** Sentence markers `[1a], [1b], [2a]` from DI `language_spans` leaked through Route 3 synthesis, causing the LLM to hallucinate hundreds of citations (360+ markers in context).

**Fix (committed d2cc988e):**
- Added `strip_sentence_markers()` utility + `_SENTENCE_CITATION_RE` regex at module level in `synthesis.py`
- Applied structurally in **both** Route 2 (`synthesize()`) and Route 3 (`synthesize_with_graph_context()`)
- Added `sentence_citation_map.clear()` in both paths
- Added per-chunk sentence caps: `ROUTE2_MAX_SENTENCES_PER_CHUNK=8`, `ROUTE3_MAX_SENTENCES_PER_CHUNK=8`
- Updated `scripts/benchmark_route3_community_prompt.py` to import shared function instead of local copy

**Files changed:**
- `src/worker/hybrid_v2/pipeline/synthesis.py` — structural strip + sentence caps
- `scripts/benchmark_route3_community_prompt.py` — import shared utility

### 2. Doc-Scope Retrieval (Prior Session, Verified) ✅

IDF-weighted entity→document voting, doc-filtered Cypher, doc-coherence denoising (Pass 7). Benchmark results:

| Combo | F1 | Precision | Recall | Ctx Chars |
|---|---|---|---|---|
| baseline+gpt-5-mini | 0.479 | 0.579 | 0.456 | 26,640 |
| doc_scope+gpt-5-mini | 0.492 | 0.642 | 0.440 | 13,808 |
| baseline+gpt-4.1-mini | 0.501 | 0.459 | 0.579 | 26,640 |
| doc_scope+gpt-4.1-mini | 0.521 | 0.487 | 0.585 | 13,808 |

### 3. Chunking & Embedding Pipeline Research ✅

Full codebase audit of how documents are chunked and embedded. Key findings:

- **Table row linearizations exist in metadata but are NEVER embedded** (`_extract_table_row_sentences()`)
- **All content types embedded identically** — no content-type routing
- **DI `language_spans` are noisy** — ~40% are table cells, form labels, headers
- **avg chunk size 641 tokens** — too coarse for precision-critical queries
- **Chunk noise filters** are post-retrieval soft penalties only (don't fix root cause)

### 4. Chunking Strategy Analysis Document ✅

Created `ANALYSIS_CHUNKING_STRATEGY_DEEP_DIVE_2026-02-10.md` covering:
- Full current architecture documentation
- Two improvement options with pros/cons
- Four mature industry strategies (references)
- Phase 0 experiment design
- Production scale estimates
- Decision framework by customer domain

---

## What Is NOT Done — Todo List

### Immediate (Tomorrow Morning)

- [ ] **Build Phase 0 experiment script** (`scripts/experiment_chunking_strategy.py`)
  - Pull DI paragraphs + table row linearizations from chunk metadata in Neo4j
  - Embed with voyage-context-3 `contextualized_embed()`
  - Run benchmark queries as cosine similarity top-k
  - Compare F1/precision/recall across 4 variants (baseline, paragraphs+tables, filtered sentences, hybrid)
  - ~2-3 hours of work

### Short-Term (This Week)

- [ ] **Implement Option 1: Table row promotion** (if Phase 0 shows improvement)
  - Promote table row sentences from metadata → standalone TextChunk nodes
  - Embed separately with voyage-context-3
  - Link via PART_OF → parent chunk
  - Add `chunk_type = "table_row"` property
  - Update retrieval to include table-row chunks
  - ~2-3 days

- [ ] **Reduce max_tokens from 1500 → 800** (if Phase 0 supports smaller chunks)
  - Change `SectionChunkConfig.max_tokens` in `chunker.py`
  - Re-index test corpus
  - Re-benchmark
  - ~1 day

- [ ] **Add content-type embedding prefixes** (experimental)
  - Prepend "Table row: " for table-row chunks
  - Prepend "Key-value: " for KVP chunks
  - Measure impact
  - ~0.5 day

### Medium-Term (Next Sprint)

- [ ] **Implement Option 2: Sentence-level retrieval** (if Phase 0 shows significant improvement)
  - New Sentence node type in Neo4j
  - Sentence extraction pipeline with DI noise filtering
  - Sentence vector index (`sentence_embeddings_v2`)
  - Parent-chunk expansion in retrieval path
  - ~1-2 weeks

- [ ] **Production deployment of chunking improvements**
  - Full re-index of all customer corpora
  - Update retrieval paths for new node types
  - Benchmark against production traffic

### Backlog

- [ ] **DI sentence noise filtering pipeline** — needed for both Option 1 and Option 2
- [ ] **spaCy integration for clean sentence boundaries** — alternative to DI language_spans
- [ ] **LLM-based sentence segmentation** — highest quality, highest cost option
- [ ] **Contextual header stacking** — prepend section_path to chunk text before embedding
- [ ] **Benchmark expansion** — need more queries, especially table-specific and domain-specific

---

## Environment Quick Reference

```
Neo4j:       neo4j+s://a86dcf63.databases.neo4j.io  (user=neo4j)
Azure OpenAI: graphrag-openai-8476.openai.azure.com  (AAD auth)
Voyage AI:   voyage-context-3, 2048-dim
Test corpus: test-5pdfs-v2-fix2 (5 docs, 18 chunks, 347 sentences)

Production env vars:
  DOC_SCOPE_ENABLED=1
  DOC_SCOPE_MIN_SCORE=1.5
  DENOISE_DOC_COHERENCE=1
  DOC_COHERENCE_PENALTY=0.2
  ROUTE2_MAX_SENTENCES_PER_CHUNK=8
  ROUTE3_MAX_SENTENCES_PER_CHUNK=8
  DENOISE_SCORE_WEIGHTED=1
  DENOISE_COMMUNITY_FILTER=1
  COMMUNITY_PENALTY=0.3
  DENOISE_SCORE_GAP=1
  SCORE_GAP_THRESHOLD=0.5
  SCORE_GAP_MIN_KEEP=6
  DENOISE_SEMANTIC_DEDUP=1
  SEMANTIC_DEDUP_THRESHOLD=0.92
```

## Key Files to Know

| File | What It Does |
|---|---|
| `src/worker/hybrid_v2/pipeline/synthesis.py` | Stage 3 synthesis (Route 2 + Route 3), citation fix, doc-scope |
| `src/worker/hybrid_v2/indexing/section_chunking/chunker.py` | Section-aware chunking (100-1500 tokens) |
| `src/worker/services/document_intelligence_service.py` | DI processing, table linearization, sentence extraction |
| `src/worker/hybrid_v2/embeddings/voyage_embed.py` | Voyage contextual embedding with bin-packing |
| `src/worker/hybrid_v2/pipeline/chunk_filters.py` | Post-chunking noise filters |
| `src/worker/hybrid_v2/indexing/lazygraphrag_pipeline.py` | Pipeline entry point for chunking |
| `ANALYSIS_CHUNKING_STRATEGY_DEEP_DIVE_2026-02-10.md` | Full analysis doc (created today) |

## Git State

```
Branch: main
HEAD:   d2cc988e — "fix: structural citation explosion fix + doc-scope retrieval"
Status: clean (all changes committed and pushed)
```

---

*Ready for Phase 0 experiment tomorrow morning. Start with the analysis doc, then build the script.*
