# Handover - February 7, 2026

## Summary

Today's session covered **three phases**:
1. **Route 4 DRIFT** improvements and **Router LLM** prompt refinements (morning)
2. **Q-G5 root cause investigation** — coverage gap fill fix + synthesis prompt fix (afternoon)  
3. **`include_context` feature** for all routes + **sentence-level citations for Route 2** (evening)

---

## Completed Work (Evening Session — include_context & Sentence Citations)

### 6. `include_context` Feature (All Routes)

Returns the full LLM evidence context in API response metadata for debugging retrieval vs LLM issues.

**Commits:**
- `2df6a121` feat: add include_context param to return full LLM evidence in API response
  - `HybridQueryRequest`: added `include_context: bool` field
  - Route 3: threaded through `synthesize_with_graph_context()` → metadata
  - Benchmark script: `--include-context` flag stores `llm_context` in each run
- `82cf0c74` feat: thread include_context through Route 2 and Route 4 synthesis
  - `synthesize()` (non-graph path): added `include_context` param, returns `llm_context`
  - Route 2 + Route 4: pass through and surface in metadata

### 7. Sentence-Level Citations for Route 2

Route 2 now produces `[1a]`, `[1b]`, `[1c]` sub-citations from Azure DI language span boundaries, matching what Route 3 already does via `synthesize_with_graph_context()`.

**Commit:** `1e522668` feat: sentence-level citations for Route 2 via Azure DI language spans

Changes:
- `BaseRouteHandler._fetch_language_spans()` — moved from Route 3, shared by all routes
- `synthesize()` — new `language_spans_by_doc` param, sentence segmentation in `_build_cited_context()`
- Route 2 Stage 2.2.5 — fetches doc IDs from text chunks, gets language spans, passes to synthesize
- Route 3 — removed duplicate method, now inherits from base
- Controlled by `ROUTE2_SENTENCE_CITATIONS=1` env var (default: enabled)
- Chunks without `start_offset`/`end_offset` gracefully fall back to chunk-level `[N]` citations

### 8. Q-G5 Root Cause: Proven with Graph Evidence

- **BM25 "remedies dispute resolution"** → 6 hits ALL from Builders Limited Warranty, 0 from Purchase Contract
- **BM25 "default legal fees"** → Purchase Contract at score 3.47 (what coverage gap fill finds)
- Coverage gap fill was the ONLY retrieval path that could bridge the vocabulary mismatch
- Fix (`cb80c94d`): removed `if coverage_mode:` gate so coverage gap fill always runs
- 5/6 benchmark miss explained: LLM used "failure to pay" phrasing instead of "default" — retrieval worked, LLM phrasing variance only

---

## Proposed Future Optimization (Route 2 Double-Fetch)

**Issue:** Route 2 currently calls `_retrieve_text_chunks(evidence_nodes)` twice:
1. In Stage 2.2.5 (to get doc IDs for language spans fetch)
2. Inside `synthesize()` (to get the actual chunks for synthesis)

**Proposed fix:** Add a `pre_fetched_chunks` parameter to `synthesize()` so Route 2 can pass the already-retrieved chunks, skipping the redundant Neo4j query. Not urgent — data is small (<20 chunks) and correctness is unaffected.

```python
# In synthesize():
async def synthesize(self, ..., pre_fetched_chunks=None):
    text_chunks = pre_fetched_chunks or await self._retrieve_text_chunks(evidence_nodes)
```

---

## Completed Work (Morning Session — Route 4 & Router)

### 1. Route 4 Ground Truth Expansion (14 → 16 + 2 observations)

**File:** `scripts/test_route4_comprehensive_sentence.py`

- Added **B6**: Automatic opener vs door operator terminology
- Added **B7**: Power system (contract) vs operation parts (invoice) — confirmed REAL via Neo4j Table nodes
- Added **D-category** "Observations" (not strict inconsistencies but demonstrate analytical depth):
  - **D1**: Tax field N/A on invoice (Table row: SUBTOTAL→TAX, 29900.00→N/A)
  - **D2**: Entity role variation (Contoso Ltd=Owner in warranty/tank/property-mgmt vs Contoso Lifts LLC=Contractor in invoice/contract)

**Commits:**
- `4a7cddc1` scoring: add B7 power-system/operation-parts (16 GT items)
- `377821b9` scoring: add D-category observations (Tax N/A, Role Swaps)

**All 3 synthesis models score 18/18** (16 core + 2 obs):
- gpt-5.1: 18/18
- gpt-4.1: 18/18
- gpt-4.1-mini: 18/18

### 2. DRIFT Decomposition Multi-line Parser Fix

**Previous commits (from earlier session):**
- Fixed `_drift_decompose()` to properly handle multi-line sub-questions
- Added BAD/GOOD examples to prompt for complete self-contained sentences
- Seeds jumped from 0-13 → 13-18 after fix

### 3. Route 4 Synthesis Markdown Formatting

**Commit:** `cdadfd94` refactor: standardize all LLM outputs to markdown format

- Updated synthesis prompts to output structured markdown
- Entity discovery improved: 13-18 seeds (plain) → **196 seeds** (markdown)
- Response quality: Clean hierarchical sections with proper formatting

**Commit:** `68652b0a` fix: restore synthesis prompt instructions lost in markdown refactor

### 4. Router LLM Prompt Refinements

**File:** `src/worker/hybrid_v2/router/main.py`

Fixed 2 misclassifications:
- **Q-V4**: "List the 3 installment amounts" → now routes to **local_search** (was drift, 10-80s penalty)
- **Q-N6**: "Which documents governed by CA?" → now routes to **local_search** (was global, 25-40s)

Changes made:
- Added "Lists of specific items within a document" to local_search
- Added "Simple document identification by explicit mentions" to local_search
- Restricted drift trigger: "which document" only for **calculated conditions, ranking, or cross-referencing**
- Added critical distinction: `"Which contracts are in NY?" (local)` vs `"Which contract has the best payment terms?" (drift)`

**Note:** Router changes are uncommitted pending testing.

### 5. Route 4 Benchmark Run

**File:** `benchmarks/route4_drift_multi_hop_20260207T141414Z.json`

19 questions × 3 repeats:

| Metric | Value |
|--------|-------|
| Positive Tests Passed | 6/10 (containment ≥ 0.5) |
| Negative Tests Passed | 8/9 |
| Avg Containment | 0.54 |
| Avg F1 | 0.11 |
| Latency P50 | 38.6s |
| Latency P95 | 134.4s |

**Passed:** Q-D1, Q-D2, Q-D3, Q-D4, Q-D6, Q-D8

**Failed positive tests:**
- Q-D5: 0.00 containment
- Q-D7: 0.22 containment (0.4s latency - suspiciously fast, may have errored)
- Q-D9: 0.00 containment
- Q-D10: 0.00 containment

**Failed negative test:**
- Q-N7: Should have returned "not found" but didn't

---

## Open TODOs

### Immediate (Feb 8)

1. **Deploy to Azure Container Apps** — commits `2df6a121` through `1e522668` are pushed but not deployed yet
2. **Run Route 2 benchmark** — test sentence-level citations are working in prod
3. **Run Route 3 benchmark** — verify no regression from `_fetch_language_spans` refactor (moved to base)
4. **Run Route 4 benchmark** — verify `include_context` threading doesn't break anything

### High Priority

1. **Investigate Q-D5, Q-D7, Q-D9, Q-D10 failures**
   - Check if ground truth is accurate
   - Verify retrieval is finding relevant chunks
   - Q-D7 had 0.4s latency — may be a timeout/error, not a real answer

2. **Investigate Q-N7 failure**
   - This is a negative test that should return "not found"
   - Verify the question and expected behavior

3. **Commit router prompt changes**
   - File: `src/worker/hybrid_v2/router/main.py`
   - Test Q-V4 and Q-N6 routing before committing

### Medium Priority

4. **Re-run router benchmark** to verify Q-V4 and Q-N6 now route correctly

5. **Consider adding more observations to D-category** if models consistently surface other real cross-document insights

### Low Priority

6. **Latency optimization** — P95 is 134.4s, some queries take 150s+

---

## Key Files Modified Today

| File | Status | Description |
|------|--------|-------------|
| `src/worker/hybrid_v2/pipeline/synthesis.py` | ✅ Committed | `include_context` + `language_spans_by_doc` in `synthesize()`, sentence segmentation in `_build_cited_context()` |
| `src/worker/hybrid_v2/routes/base.py` | ✅ Committed | `_fetch_language_spans()` shared method |
| `src/worker/hybrid_v2/routes/route_2_local.py` | ✅ Committed | `include_context` + sentence citations (Stage 2.2.5) |
| `src/worker/hybrid_v2/routes/route_3_global.py` | ✅ Committed | Removed duplicate `_fetch_language_spans()`, inherits from base |
| `src/worker/hybrid_v2/routes/route_4_drift.py` | ✅ Committed | `include_context` threading |
| `src/worker/hybrid_v2/orchestrator.py` | ✅ Committed | `include_context` pass-through |
| `src/api_gateway/routers/hybrid.py` | ✅ Committed | `include_context` field on `HybridQueryRequest` |
| `scripts/benchmark_route3_global_search.py` | ✅ Committed | `--include-context` flag |
| `scripts/test_route4_comprehensive_sentence.py` | ✅ Committed | 16+2 GT scoring |
| `src/worker/hybrid_v2/router/main.py` | ⚠️ Uncommitted | Q-V4/Q-N6 routing fix |
| `benchmarks/route4_drift_multi_hop_20260207T141414Z.json` | New | Route 4 benchmark |
| `benchmarks/route4_drift_multi_hop_20260207T141414Z.md` | New | Route 4 benchmark report |

---

## Neo4j Credentials (for verification queries)

```
URI: neo4j+s://a86dcf63.databases.neo4j.io
User: neo4j
Password: uvRJoWeYwAu7ouvN25427WjGnU37oMWaKN_XMN4ySKI
Database: neo4j
```

**Group ID:** `test-5pdfs-v2-fix2`

---

## Recent Commits

```
1e522668 feat: sentence-level citations for Route 2 via Azure DI language spans
82cf0c74 feat: thread include_context through Route 2 and Route 4 synthesis
2df6a121 feat: add include_context param to return full LLM evidence in API response
651e64d3 docs: add handover file 2026-02-07
68652b0a fix: restore synthesis prompt instructions lost in cdadfd94 markdown refactor
7eee442d Add benchmark postfix results 2026-02-07
cdadfd94 refactor: standardize all LLM outputs to markdown format
2aebf944 router: upgrade to gpt-5.1 for 97.6% accuracy (from 92.7%)
cb80c94d fix(route3): always run coverage gap fill for global search
377821b9 scoring: add D-category observations (Tax N/A, Role Swaps)
4a7cddc1 scoring: add B7 power-system/operation-parts (16 GT items)
```

---

## Quick Resume Commands

```bash
# Deploy to Azure Container Apps (MUST DO FIRST on Feb 8)
cd /afh/projects/graphrag-orchestration && azd deploy

# Run Route 3 benchmark (verify no regression from _fetch_language_spans refactor)
python3 scripts/benchmark_route3_global_search.py --repeats 3

# Run Route 3 benchmark WITH include_context (debug retrieval)
python3 scripts/benchmark_route3_global_search.py --repeats 1 --include-context

# Run Route 4 benchmark (3 repeats, full question bank)
python3 scripts/benchmark_route4_drift_multi_hop.py --repeats 3

# Run Route 2 benchmark (if script exists, otherwise manual curl test)
# Test sentence citations on Route 2:
curl -s -X POST -H "Authorization: Bearer $TOKEN" -H "Content-Type: application/json" \
  -d '{"query":"What are Contoso payment terms?","group_id":"test-5pdfs-v2-fix2","response_type":"summary","force_route":"local_search"}' \
  "https://graphrag-api.salmonhill-df6033f3.swedencentral.azurecontainerapps.io/hybrid/query" | python3 -m json.tool

# Check uncommitted changes
git status --short

# Check specific failing question (e.g., Q-D5)
python3 scripts/benchmark_route4_drift_multi_hop.py --repeats 1 --filter-qid Q-D5
```
