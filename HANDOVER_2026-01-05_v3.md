# Handover — 2026-01-05

## Where we are
We focused on Route 3 (Hybrid global search) quality for Q-G1 (“Across the agreements, list the termination/cancellation rules you can find.”) and on distinguishing **root cause** vs “tweak-first”.

### Key findings (root cause first)
1) **A “Not found” outcome can be purely a wrong `group_id`** (no indexed Neo4j data), not a retrieval regression.
- With `group_id=test-5pdfs-1767607148075079644`:
  - Community generation returned **0 communities**.
  - Entity search + sampling returned **0 entities**.
  - Enhanced graph retriever returned **0 source chunks**.
  - Route 3 triggered `route_3_negative_detection_no_graph_signal` → response “not found”.

2) With the previously known-good group, Route 3 works and Q-G1 is the expected “partial” answer.
- With `group_id=test-5pdfs-1767429340223041632`:
  - `multi_document_sampling` covers 5 docs.
  - `route_3_evidence_debug` shows non-zero source chunks across docs.
  - Q-G1 theme coverage baseline around **~38%** (3/8 terms).

3) **Why Q-G1 was ~38%** (actual content gap, not just metric):
- Evidence context often included purchase contract chunks, but not the specific cancellation clause chunk (“3 business days”, “full refund”, “deposit forfeited”).
- Without that clause present in the provided evidence chunks, the LLM can’t reliably synthesize those terms.

4) A targeted evidence boost can close the gap.
- After enabling the experimental keyword-boost, Q-G1 jumped to **~88%** (7/8 terms) in a 1-repeat run.
- The response explicitly included:
  - “cancel within 3 business days”,
  - “full refund”,
  - “deposit is forfeited”.

## What changed in code
### 1) Experimental keyword-boost chunk retrieval
- Added a new method to retrieve chunks lexically (diversified per document):
  - `EnhancedGraphRetriever.get_keyword_boost_chunks()`
  - File: `graphrag-orchestration/app/hybrid/pipeline/enhanced_graph_retriever.py`

- Wired into Route 3 (Stage 3.3) but **gated behind env var**:
  - `ROUTE3_KEYWORD_BOOST=1` enables.
  - Default remains unchanged.
  - File: `graphrag-orchestration/app/hybrid/orchestrator.py`

### 2) Evidence debug logging (gated)
- Added optional evidence logging to confirm which chunks/docs are passed to synthesis:
  - `ROUTE3_DEBUG_EVIDENCE=1` logs doc_counts + chunk_samples.
  - File: `graphrag-orchestration/app/hybrid/orchestrator.py`

### 3) Theme metric normalization (tiny tweak)
- Updated normalization in theme coverage scoring so “non-transferable” matches expected “not transferable”.
  - File: `scripts/benchmark_route3_global_search.py`

## Deployment / environment state
### Azure Container App
- App: `graphrag-orchestration`
- RG: `rg-graphrag-feature`
- URL: https://graphrag-orchestration.salmonhill-df6033f3.swedencentral.azurecontainerapps.io

### Current env vars (IMPORTANT)
During A/B testing we enabled:
- `ROUTE3_DEBUG_EVIDENCE=1`
- `ROUTE3_KEYWORD_BOOST=1`

If we want baseline behavior again:
- Set `ROUTE3_KEYWORD_BOOST=0`
- (Optional) set `ROUTE3_DEBUG_EVIDENCE=0`

## How to reproduce
### Benchmark script
- Script: `scripts/benchmark_route3_global_search.py`

Known-good group id:
- `test-5pdfs-1767429340223041632`

Command (Q-G1 only, 1 repeat):
```bash
python3 scripts/benchmark_route3_global_search.py \
  --url https://graphrag-orchestration.salmonhill-df6033f3.swedencentral.azurecontainerapps.io \
  --group-id test-5pdfs-1767429340223041632 \
  --repeats 1 \
  --max-questions 1 \
  --timeout 240
```

Bad group id example (causes “not found”):
- `test-5pdfs-1767607148075079644`

## Outputs produced today
- `benchmarks/route3_global_search_20260105T151039Z.json` (bad group id, not found)
- `benchmarks/route3_global_search_20260105T151624Z.json` (baseline, ~38%)
- `benchmarks/route3_global_search_20260105T151840Z.json` (keyword boost on, ~88%)

## TODO (for tomorrow)
1) **Decide product stance on keyword-boost**
- Keep it as an opt-in debugging switch only?
- Or enable by default for termination/cancellation queries?

2) **If enabling by default, tighten scope/safety**
- Confirm it cannot “overpower” normal evidence selection on unrelated queries.
- Consider enabling only when:
  - query contains strong termination/cancellation signals, AND
  - initial evidence lacks those clauses (e.g., 0 chunks from purchase contract section paths).

3) **Verify with more repeats and more questions**
- Run Q-G1 with `--repeats 5` baseline vs boost to confirm stability.
- Spot-check Q-G7 / Q-G9 to ensure no regressions.

4) **Validate group id hygiene**
- Update docs/scripts to discourage using stale `last_test_group_id.txt` blindly.
- Consider printing a clear warning in benchmark output when Neo4j returns zero entities/chunks.

5) **Optional: improve evidence debug UX**
- Current debug logs include chunk previews; decide whether to keep previews in production logs or limit to section/doc counts.
