# TODO List - January 15, 2026
**Project:** GraphRAG Orchestration - HippoRAG 2 Investigation
**Status:** Debug endpoint deployed, awaiting analysis results

---

## üî¥ CRITICAL - Immediate Actions

### 1. Complete Deployment & Debug Analysis
**Priority:** P0 - BLOCKING  
**ETA:** 5-10 minutes

- [ ] Monitor deployment completion
  ```bash
  az containerapp revision list -n graphrag-orchestration -g rg-graphrag-feature \
    --query "[?properties.active].name" -o tsv
  ```
  - Current: Revision 0000220 deploying
  - Target: Revision 0000220 active with 100% traffic

- [ ] Call debug endpoint once active
  ```bash
  curl -s -H "X-Group-ID: test-5pdfs-1768486622652179443" \
    "https://graphrag-orchestration.salmonhill-df6033f3.swedencentral.azurecontainerapps.io/hybrid/debug/section_similarity_distribution" \
    | python3 -m json.tool > /tmp/similarity_dist_$(date +%Y%m%d_%H%M%S).json
  ```

- [ ] Analyze similarity distribution
  - Check p90, p95, p99 percentiles
  - Compare against current threshold (0.80)
  - Identify optimal threshold value

---

## üü† HIGH - Parameter Tuning (If Needed)

### 2. Fix Similarity Threshold
**Priority:** P1 - Dependent on debug results  
**Condition:** If p95 < 0.80

**Steps:**
- [ ] Update `lazygraphrag_pipeline.py` line 1383
  ```python
  # OLD
  similarity_threshold = 0.80
  
  # NEW (example - use actual p75 value from debug output)
  similarity_threshold = 0.75  # or 0.70 based on analysis
  ```

- [ ] Commit and push changes
  ```bash
  git add app/hybrid/indexing/lazygraphrag_pipeline.py
  git commit -m "Lower similarity threshold to <value> based on debug analysis"
  git push
  ```

- [ ] Deploy updated code
  ```bash
  ./deploy-graphrag.sh
  ```

- [ ] Wait for deployment (~5 min)
  - Monitor revision number increment

### 3. Re-index Test Group
**Priority:** P1 - After threshold fix

- [ ] Get document IDs for test group
  ```bash
  curl -H "X-Group-ID: test-5pdfs-1768486622652179443" \
    "https://graphrag-orchestration.salmonhill-df6033f3.swedencentral.azurecontainerapps.io/hybrid/documents" \
    | python3 -m json.tool > /tmp/docs.json
  ```

- [ ] Trigger re-indexing
  ```bash
  # Use document IDs from previous step
  curl -X POST -H "X-Group-ID: test-5pdfs-1768486622652179443" \
    -H "Content-Type: application/json" \
    -d '{"document_ids": ["<id1>", "<id2>", "<id3>", "<id4>", "<id5>"]}' \
    "https://graphrag-orchestration.salmonhill-df6033f3.swedencentral.azurecontainerapps.io/hybrid/index/reindex"
  ```

- [ ] Monitor indexing progress (~9-10 minutes expected)
  ```bash
  watch -n 30 'curl -s -H "X-Group-ID: test-5pdfs-1768486622652179443" \
    "https://graphrag-orchestration.salmonhill-df6033f3.swedencentral.azurecontainerapps.io/hybrid/index/status"'
  ```

- [ ] Verify edge creation
  - Expected: `semantic_similarity_edges > 0`
  - Target: ~5 edges per section (max_edges_per_section = 5)

---

## üü° MEDIUM - Code Investigation (Alternative Path)

### 4. Debug Logic Issue (If p95 ‚â• 0.80)
**Priority:** P2 - Only if threshold is not the issue  
**Condition:** If p95 ‚â• 0.80 but still 0 edges

**Investigation Areas:**

- [ ] Check `_build_section_similarity_edges()` logic (line 1365-1493)
  - Verify doc_id filtering: `if sec1_doc_id != sec2_doc_id`
  - Check embedding linkage: sections have valid embeddings
  - Validate max_edges logic: `sec1_edges < max_edges_per_section`

- [ ] Add detailed logging
  ```python
  # Insert after line 1420
  logger.info(f"Processing {len(sections)} sections", 
              total_pairs=len(sections) * (len(sections) - 1) / 2,
              cross_doc_pairs=cross_doc_count)
  ```

- [ ] Check Neo4j data integrity
  ```cypher
  // Run in Neo4j Browser
  MATCH (s:Section {group_id: "test-5pdfs-1768486622652179443"})
  WHERE s.embedding IS NOT NULL
  RETURN s.doc_id, count(*) as sections
  ORDER BY s.doc_id
  ```

- [ ] Validate embedding dimensions
  ```cypher
  MATCH (s:Section {group_id: "test-5pdfs-1768486622652179443"})
  WHERE s.embedding IS NOT NULL
  RETURN size(s.embedding) as dim, count(*) as count
  ```

---

## üü¢ LOW - Feature Testing

### 5. Test Route 4 Deep Reasoning
**Priority:** P3 - After edge creation verified  
**Prerequisite:** semantic_similarity_edges > 0

- [ ] Prepare test questions from `QUESTION_BANK_ROUTE4_DEEP_REASONING_2026.md`

- [ ] Run baseline tests (without confidence loop)
  ```bash
  # Force route 4 without re-decomposition
  curl -X POST -H "X-Group-ID: test-5pdfs-1768486622652179443" \
    -H "Content-Type: application/json" \
    -d '{"question": "<question>", "route": 4, "enable_confidence_loop": false}' \
    "https://graphrag-orchestration.salmonhill-df6033f3.swedencentral.azurecontainerapps.io/hybrid/query"
  ```

- [ ] Run with confidence loop enabled
  ```bash
  curl -X POST -H "X-Group-ID: test-5pdfs-1768486622652179443" \
    -H "Content-Type: application/json" \
    -d '{"question": "<question>", "route": 4, "enable_confidence_loop": true}' \
    "https://graphrag-orchestration.salmonhill-df6033f3.swedencentral.azurecontainerapps.io/hybrid/query"
  ```

- [ ] Compare results:
  - Answer quality (subjective)
  - Confidence scores
  - Number of re-decomposition iterations
  - Response times

### 6. Benchmark Full Suite
**Priority:** P3 - After Route 4 validation

- [ ] Run Route 3 (local search) benchmarks
  ```bash
  python benchmark_routes.py --route 3 --group test-5pdfs-1768486622652179443 \
    > bench_route3_hipporag2_$(date +%Y%m%d_%H%M%S).txt
  ```

- [ ] Run Route 4 (deep reasoning) benchmarks
  ```bash
  python benchmark_routes.py --route 4 --group test-5pdfs-1768486622652179443 \
    > bench_route4_hipporag2_$(date +%Y%m%d_%H%M%S).txt
  ```

- [ ] Compare against baseline
  - File: `bench_baseline_quick.txt`
  - Metrics: accuracy, recall, response time
  - Focus: questions requiring cross-document reasoning

---

## üìã BACKLOG - Future Improvements

### 7. Optimize Section Embedding
**Priority:** P4 - Performance optimization

- [ ] Experiment with chunk sampling strategies
  - Current: Up to 3 chunks, 500 chars each
  - Test: 5 chunks, 1000 chars
  - Test: Smart selection (highest entity density)

- [ ] Evaluate embedding models
  - Current: Azure OpenAI text-embedding-ada-002
  - Test: text-embedding-3-large (higher dimension)

### 8. Dynamic Threshold Adjustment
**Priority:** P4 - Smart tuning

- [ ] Implement per-corpus threshold calibration
  - Analyze similarity distribution at index time
  - Set threshold at p75 or p80 automatically
  - Store in group metadata

- [ ] Add threshold as query-time parameter
  - Allow override for specific queries
  - Useful for precision/recall tuning

### 9. Edge Quality Metrics
**Priority:** P4 - Validation tools

- [ ] Add edge validation endpoint
  - Return sample edges with similarity scores
  - Show connected document pairs
  - Visualize thematic connections

- [ ] Track edge usage in queries
  - Log when SEMANTICALLY_SIMILAR edges are traversed
  - Measure impact on answer quality
  - A/B test with/without edges

---

## ‚úÖ COMPLETED

- [x] Implement HippoRAG 2 features (commit 9511973)
  - Section embeddings (_embed_section_nodes)
  - SEMANTICALLY_SIMILAR edges (_build_section_similarity_edges)
  - Confidence loop (route4_deep_reasoning_rewrite)

- [x] Deploy GPT-5.1 model configuration
  - DataZoneStandard SKU
  - Version: 2025-11-13

- [x] Index test group (test-5pdfs-1768486622652179443)
  - 5 PDFs, 74 chunks, 401 entities, 828 relationships
  - 51 section embeddings created
  - 0 semantic_similarity_edges (under investigation)

- [x] Create debug endpoint (commit 082cfc0 + 35fa4af)
  - `/hybrid/debug/section_similarity_distribution`
  - Computes cross-document similarity distribution
  - Analyzes threshold impact

- [x] Fix import errors
  - Neo4jStore ‚Üí Neo4jStoreV3
  - Add initialization parameters (uri, username, password)

---

## üìù Notes & Context

### Threshold Decision Criteria
- **If p95 < 0.75:** Lower to 0.70
- **If p95 0.75-0.79:** Lower to 0.75
- **If p95 ‚â• 0.80:** Investigate code logic
- **Goal:** Create meaningful edges without noise

### Expected Edge Counts
- 51 sections √ó 5 max edges = **255 edges max**
- Realistic target: **100-200 edges** (considering cross-doc filtering)
- Current: **0 edges** (bug or parameter issue)

### Query Patterns Requiring Edges
1. **Cross-document synthesis:** "Compare warranty terms across properties"
2. **Thematic clustering:** "What common issues appear in all documents?"
3. **Latent transitions:** "How does invoice pricing relate to property features?"

### Performance Baselines
- Indexing: 545s for 5 docs (acceptable)
- Query (Route 3): ~3-8s (good)
- Query (Route 4): TBD (expected 10-20s with confidence loop)

---

## üîó Quick Links

- **Handover Doc:** [HANDOVER_20260115.md](./HANDOVER_20260115.md)
- **Architecture:** [ARCHITECTURE_DESIGN_LAZY_HIPPO_HYBRID.md](./ARCHITECTURE_DESIGN_LAZY_HIPPO_HYBRID.md)
- **Test Questions:** [QUESTION_BANK_ROUTE4_DEEP_REASONING_2026.md](./QUESTION_BANK_ROUTE4_DEEP_REASONING_2026.md)
- **Container App:** https://graphrag-orchestration.salmonhill-df6033f3.swedencentral.azurecontainerapps.io
- **Neo4j Browser:** http://neo4j-graphrag-23987.swedencentral.azurecontainer.io:7474

---

**Last Updated:** 2026-01-15 15:05 UTC  
**Next Review:** After debug endpoint results (ETA: 15-20 minutes)
